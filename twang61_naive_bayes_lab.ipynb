{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42f956232f320486dee7bc121691a4e9",
     "grade": false,
     "grade_id": "cell-588eb434a3567ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Lab: Apply Naive Bayes to classify movie reviews with scikit-learn\n",
    "====\n",
    "\n",
    "![](https://imgs.xkcd.com/comics/star_ratings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bc0818274dfe91af6c7d9234bc497454",
     "grade": false,
     "grade_id": "cell-5cc85b93d38670f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "By The End Of This Lab You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Programmatically download data from the Internet\n",
    "- Fit Naive Bayes model with scikit-learn\n",
    "- Improve model performance to be better than the results from a published peer-reviewed paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "038a241a84c2a7691874c084c448e2e6",
     "grade": false,
     "grade_id": "cell-74ffb01e1d026bb3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You are going to apply the Data Science workflow to classifying movie reviews as positive or negative. \n",
    "\n",
    "__Data Science Workflow:__\n",
    "\n",
    "1. Ask\n",
    "2. Acquire\n",
    "3. Process\n",
    "4. Model\n",
    "5. Deliver \n",
    "\n",
    "You are going to use the Internet Movie Database ([imdb.com](www.imdb.com)) data from the seminal [Pang et al. (2002)](http://www.cs.cornell.edu/home/llee/papers/sentiment.pdf) paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4600387f8aaa5ddb1e85aff32be5b145",
     "grade": false,
     "grade_id": "cell-6b5214b9b11062d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "1) Ask: \n",
    "----\n",
    "\n",
    "Can a simple machine learnning model predict if movie review is positive or negative?\n",
    "\n",
    "Can we improve model performance to be better than state-of-the-art in 2002?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "de4d7e1b80459f44e262cd15a73d5498",
     "grade": false,
     "grade_id": "cell-1c5a7bc50d2b12db",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "2) Acquire\n",
    "----\n",
    "\n",
    "You are going to use movie review data from http://www.cs.cornell.edu/People/pabo/movie-review-data/, specifically the `polarity dataset v2.0 (3.0Mb)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71a1725165e6089dffff17873e35bbf7",
     "grade": false,
     "grade_id": "cell-15cd187291b14aba",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e9862f80556d11daaa33f2f9e32db2bf",
     "grade": false,
     "grade_id": "cell-c680f108d648030e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = \"http://www.cs.cornell.edu/People/pabo/movie-review-data/\"\n",
    "path = \".\"\n",
    "filename = \"review_polarity.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "857097cec54bb8ae1b63a8121a4db5e7",
     "grade": false,
     "grade_id": "cell-d80194fc50e3b03b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def download_and_unzip_data(url: str, path: str, filename: str) -> None:\n",
    "    \"\"\"Write code that retrieves the zipped file and unzips it.\n",
    "    Check if file is local, if not then retrieve it.\n",
    "    Check if files are unzipped, if not then unzip them.\n",
    "    \"\"\"\n",
    "    # Download the data\n",
    "    if not os.path.exists(filename):\n",
    "        urlretrieve(url=os.path.join(url,filename), filename=filename)\n",
    "    # Unzip the data\n",
    "    if not os.path.exists(path+\"/txt_sentoken\"):\n",
    "        with tarfile.open(filename) as tar:\n",
    "            tar.extractall()\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f76e518a29a1109454528a0f6b1a2f6",
     "grade": true,
     "grade_id": "cell-7ff458e86e415763",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and unzipping filesâ€¦\n",
      "Files download and unzipped.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2 points\n",
    "Test code for the 'download_and_unzip_data' function. \n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "\n",
    "# Remove directory to make sure function works\n",
    "try:\n",
    "    shutil.rmtree(path+\"/txt_sentoken/\")\n",
    "except OSError:\n",
    "    print('Directory not found. Moving alongâ€¦')\n",
    "    \n",
    "# Run function\n",
    "print(\"Downloading and unzipping filesâ€¦\")\n",
    "download_and_unzip_data(url, path, filename)\n",
    "\n",
    "# NOTE: Assumes UNIX style paths names\n",
    "assert os.path.exists(path+\"/txt_sentoken\")\n",
    "assert os.path.exists(path+\"/txt_sentoken/neg\")\n",
    "assert os.path.exists(path+\"/txt_sentoken/pos\")\n",
    "assert os.path.exists(path+\"/txt_sentoken/neg/cv000_29416.txt\")\n",
    "assert os.path.exists(path+\"/txt_sentoken/pos/cv999_13106.txt\")\n",
    "assert not os.path.exists(path+\"/txt_sentoken/neg/cv999_13106.txt\")\n",
    "print('Files download and unzipped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0fc1a936af72fe4b3fe0defb2fa31116",
     "grade": false,
     "grade_id": "cell-ae4d72cf0d64e942",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "3) Process\n",
    "-----\n",
    "\n",
    "The data is already processed.\n",
    "\n",
    "Look at several reviews in your favorite text editor to get a general sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65b926dc4232c19baf4c0f1998fb78c4",
     "grade": false,
     "grade_id": "cell-4a9bef901003e9a0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . \r\n",
      "they get into an accident . \r\n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \r\n",
      "what's the deal ? \r\n",
      "watch the movie and \" sorta \" find out . . . \r\n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \r\n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn't snag this one correctly . \r\n",
      "they seem to have taken this pretty neat concept , but executed it terribly . \r\n",
      "so what are the problems with the movie ? \r\n",
      "well , its main problem is that it's simply too jumbled . \r\n"
     ]
    }
   ],
   "source": [
    "! head ./txt_sentoken/neg/cv000_29416.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7a4505f936bd25844300aa8266ab17aa",
     "grade": false,
     "grade_id": "cell-88cacb6c7b8a5b37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80fe5d0e06834e46be76e056cd1551e6",
     "grade": false,
     "grade_id": "cell-47ca072821ac2e94",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# scikit-learn assumes data in different folders belongs to different classes\n",
    "sentiment = load_files(path+'/txt_sentoken/', \n",
    "                       encoding='utf-8',\n",
    "                       random_state=42)\n",
    "sentiment.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1927cb3f0b21916abd77adf911dda773",
     "grade": false,
     "grade_id": "cell-ba2e3720ccc30c1d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d16a5a59272c6c44e6752199dd4022c0",
     "grade": false,
     "grade_id": "cell-a2d9c0820b683880",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create train/test split with labels\n",
    "train_data, test_data, train_target, test_target = train_test_split(sentiment.data,\n",
    "                                                                    sentiment.target,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d9577088f75e7298cb7da3d96bb55b1",
     "grade": false,
     "grade_id": "cell-42d90ff6540000f0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "4) Model\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e5d69247f8c280925b24bcc700b3d4cf",
     "grade": false,
     "grade_id": "cell-d577a53d958ac7a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The words need to be converted into numbers (i.e., vectorized). Machine Learning algorithms assume numeric inputs.\n",
    "\n",
    "One of the simplest methods to vectorize is based on word counts. Each word is mapped to an index. For each index, we count the number of occurrences per document. The result is a matrix with a row for each document/review and a column for each word. This matrix is called the document-term matrix.\n",
    "\n",
    "Learn more with package document [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8fde46e03d8322bf74a35743826f8673",
     "grade": false,
     "grade_id": "cell-3174b413883f70fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4444e75534ae21cb607977f635758a1",
     "grade": false,
     "grade_id": "cell-2160f00926e375c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert the words to number for both training and test data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform(train_data)\n",
    "test_features = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a172aea31a683bab9a602c0130e0d1a4",
     "grade": false,
     "grade_id": "cell-95f7c00e5b10aad2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now you can define your model. Let's start with a simple model - Naive Bayes. There are many variations of Naive Bayes, for today's lab use the multinomial variation.\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). \n",
    "suitable for classification with discrete features (e.g., word counts for text classification).\n",
    "\n",
    "Learn more [here](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7705be7d81b2a9bc187dd00e85e6c652",
     "grade": false,
     "grade_id": "cell-a73453c0bd1e2308",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be941d5bd3366c919eebdade3ad53e93",
     "grade": false,
     "grade_id": "cell-86614423074cebac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "> We decided to sample an equal number of positive and negative reviewsâ€”was that a good idea? â€” Bo Pang\n",
    "\n",
    "Thus we can use accuracy as our evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4ce3bb95f25062a1dbfe5a30c1de9ee3",
     "grade": false,
     "grade_id": "cell-5a06e1066deb0f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "97a41841dee9913446b49d5e77fc6e49",
     "grade": false,
     "grade_id": "cell-715286763a89eb4d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_nb(train_features, test_features, train_target, test_target) -> float:\n",
    "    \"\"\"Fit a NB model on the training features. \n",
    "    Then predict on the test features. \n",
    "    Return accuracy.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Define a classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(train_features, train_target)\n",
    "    # raise NotImplementedError()\n",
    "    # predicted are the trained model predictions for test reviews. It will be a vector of 1s, and 0s.\n",
    "    predicted = clf.predict(test_features)\n",
    "    assert predicted.shape == (500,) \n",
    "    return accuracy_score(predicted, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_features, train_target)\n",
    "# raise NotImplementedError()\n",
    "# predicted are the trained model predictions for test reviews. It will be a vector of 1s, and 0s.\n",
    "predicted = clf.predict(test_features)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69aa41e23d94198e943deea441c6c1bc",
     "grade": true,
     "grade_id": "cell-4298c376bc4284f4",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3 points\n",
    "Test code for the 'fit_nb' function. \n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "\n",
    "assert round(fit_nb(train_features, test_features, train_target, test_target), 3) == 0.812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "771368124a7b30170415d1ab3de423a7",
     "grade": false,
     "grade_id": "cell-80d623b27dde93b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "5) Deliver\n",
    "-----\n",
    "\n",
    "The final part of lab is improve the model to score greater than 82.90% accuracy on the test set. Have a trained model that does than the score from [the published paper](http://www.cs.cornell.edu/home/llee/papers/sentiment.pdf). Once you exceed the paper performance, you have delivered and can stop.\n",
    "\n",
    "You can tune the model by hand or write code to programmatically search for a \"good enough model\". If you write code to search, just turn in the best model. Do not submit search code.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Tune Naive Bayes\n",
    "- Pick a different algorithm\n",
    "- Engineer better features\n",
    "    - Tune count vectorizer\n",
    "    - Pick a different vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "420c9321c935fdb6174b2743d3314f4a",
     "grade": false,
     "grade_id": "cell-d76b9c52bb416dc9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Reset namespace to make sure your function contains all neccesary scikit-learn functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7138e0deaefc163ab785a1dd6bcd8596",
     "grade": false,
     "grade_id": "cell-f6f157a5e7b21eda",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48736479939840362e8e7e3deec7eaf7",
     "grade": false,
     "grade_id": "cell-5ca293c2d3a7ab3e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "229dfd013bb723fcb1bd2dade79fd253",
     "grade": false,
     "grade_id": "cell-7152867643a89eb4d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_final_model() -> float:\n",
    "    \"\"\"Fit your final model, returning accuracy. \n",
    "    Remember to add needed import statements inside of this function. \n",
    "    You should only use scikit-learn. No other packages should be used.\n",
    "    Do not modify any code that is alreay written.\n",
    "    \"\"\"\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    # Load data\n",
    "    sentiment = load_files('./txt_sentoken/', \n",
    "                           encoding='utf-8',\n",
    "                           random_state=42)\n",
    "\n",
    "    # Create train/test split with labels\n",
    "    train_data, test_data, train_target, test_target = train_test_split(sentiment.data,\n",
    "                                                                        sentiment.target,\n",
    "                                                                        random_state=42)\n",
    "    \n",
    "    ## Convert the words to number for both training and test data\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    train_features = vectorizer.fit_transform(train_data)\n",
    "    test_features = vectorizer.transform(test_data)\n",
    "    clf = SVC(C=1, \n",
    "             kernel='linear',\n",
    "             gamma=1,\n",
    "             coef0=1,\n",
    "             random_state=42)\n",
    "    clf.fit(train_features, train_target)\n",
    "    predicted = clf.predict(test_features)    \n",
    "    assert predicted.shape == (500,) \n",
    "    return accuracy_score(predicted, test_target)\n",
    "fit_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "680b4f3f431cdef6b7c2546eed33dab4",
     "grade": true,
     "grade_id": "cell-4298c3764bc4284f4",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "10 points ðŸ‘ˆ\n",
    "Test code for the 'fit_best_model' function.\n",
    "This cell should NOT give any errors when it is run, warnings are okay.\n",
    "\"\"\"\n",
    "\n",
    "assert round(fit_final_model(), 4) > .8290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a76ae034e32bf94c8fca62b6c6ccc6a9",
     "grade": false,
     "grade_id": "cell-55b376a336919412",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Bonus Cartoon\n",
    "------\n",
    "\n",
    "![](https://imgs.xkcd.com/comics/emoji_movie_reviews.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "09a2aa8aba527974e6dca328efeb0bce",
     "grade": false,
     "grade_id": "cell-ff2d070e25115ec4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
