{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c188303610552979e5c1f83f88d55d74",
     "grade": false,
     "grade_id": "cell-588eb434a3567ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Lab: Pipelines & Grid Search with scikit-learn\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c5b44421bafb950ecdb007c5b8861fd",
     "grade": false,
     "grade_id": "cell-5cc85b93d38670f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "By The End Of This Lab You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Define a Pipeline to fit several ML algorithms at a time \n",
    "- Perform Grid Search to improve performance of algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "89568de670d8936b162de23fc95062ad",
     "grade": false,
     "grade_id": "cell-b3989d3eb2c9086b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "281cbb91afc16eb05a052f3b92c9acd7",
     "grade": false,
     "grade_id": "cell-e98307ceebf48695",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "palette = \"Dark2\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0c21d0c0eb9fa1513c7530da3cee5579",
     "grade": false,
     "grade_id": "cell-9a749e5acd1298e2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b827d35d0511a4f481e3c942af508a2",
     "grade": false,
     "grade_id": "cell-1ec002f4a6f0b173",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "noisy_moons = make_moons(n_samples=10_000, noise=.15, random_state=42)\n",
    "\n",
    "sns.scatterplot(x=noisy_moons[0][:, 0],\n",
    "                y=noisy_moons[0][:, 1],\n",
    "                hue=noisy_moons[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "249cd0016650cc2c367ac7bae85982cd",
     "grade": false,
     "grade_id": "cell-cea69eb469ee7101",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_moons[0], noisy_moons[1], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2291d18d1a8ab7144716e82183e3de94",
     "grade": false,
     "grade_id": "cell-d4ccf3b83059a284",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0d5ba03ad51ac95715c37d34808104e6",
     "grade": false,
     "grade_id": "cell-b0d020e0e2ce44d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def make_pipelines() -> List[Pipeline]:\n",
    "    \"\"\"Create a pipeline for each of the following algorithms:\n",
    "    1. Logistic Regression\n",
    "    2. k-NN\n",
    "    3. Naive Bayes (Guassian)\n",
    "    4. SVM\n",
    "    5. Decision Tree\n",
    "    \n",
    "    Use default hyperparameters, expect if an algorithm takes random_state then random_state=42 \n",
    "    \n",
    "    Return a list of all the pipelines.\n",
    "    \"\"\" \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    pipelines = []\n",
    "    pipelines.append(Pipeline([('clf', LogisticRegression())]))\n",
    "    pipelines.append(Pipeline([('clf', KNeighborsClassifier())]))\n",
    "    pipelines.append(Pipeline([('clf', GaussianNB())]))\n",
    "    pipelines.append(Pipeline([('clf', SVC())]))\n",
    "    pipelines.append(Pipeline([('clf', DecisionTreeClassifier())]))\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8795c752a8f2ba7153be86fabdcbc94f",
     "grade": true,
     "grade_id": "cell-dc5d8df55e26c727",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3 points\n",
    "Test code for the 'make_pipelines' function. \n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "\n",
    "pipelines = make_pipelines()\n",
    "\n",
    "assert len(pipelines) == 5\n",
    "assert all(type(pipe) == sklearn.pipeline.Pipeline for pipe in pipelines)\n",
    "assert all(len(pipe.steps) == 1 for pipe in pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad4f651e752470fe07a5ca03fe9e884e",
     "grade": false,
     "grade_id": "cell-dd00d6ae6498bef7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_pipelines(pipelines: List[Pipeline]):\n",
    "    \"\"\"Fit each pipeline to the training data. \n",
    "    The function will automatically update the global state of each pipeline, thus needs to return nothing\n",
    "    \"\"\"\n",
    "    for pipe in pipelines:\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "fit_pipelines(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "450f29605e039cb439b8b9ad28fb88c3",
     "grade": false,
     "grade_id": "cell-2b58877e63b64e24",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def order_models_moon_data() -> List[str]:\n",
    "    \"\"\"Order models from best to worst on `score`. \n",
    "    Create the list either manually or write code.\n",
    "    Return a list of names: [..., GaussianNB]\n",
    "    \n",
    "    For informational purposes, list of scores: [0.9923, 0.9900,  0.9863, 0.8853, 0.8840]\n",
    "    Thus, GaussianNB scored the worst at 0.8840\n",
    "    \"\"\"\n",
    "    models_best_to_worst = [(pipe.steps[0][1].__class__.__name__, pipe.score(X_test, y_test)) \\\n",
    "                            for pipe in pipelines]\n",
    "    models_best_to_worst.sort(key=lambda x: x[1], reverse=True)\n",
    "    models_best_to_worst = [x[0] for x in models_best_to_worst]\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    return models_best_to_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "762b81a021e29110f00af34bde923124",
     "grade": true,
     "grade_id": "cell-f6154830dc32b195",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2 points\n",
    "Test code for the 'order_models_moon_data' function. \n",
    "NOTE: There are hidden tests. They will make sure all the models are in order\n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "\n",
    "models_best_to_worst = order_models_moon_data()\n",
    "\n",
    "assert len(models_best_to_worst) == 5\n",
    "assert models_best_to_worst[-1] == 'GaussianNB'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Glass dataset\n",
    "----\n",
    "\n",
    "6 types of glass\n",
    "\n",
    "Defined in terms of their oxide content (i.e. Na, Fe, K, etc)\n",
    "\n",
    "> The study of classification of types of glass was motivated by criminological investigation. At the scene of the crime, the glass left can be used as evidence...if it is correctly identified!\n",
    "\n",
    "Read more: https://archive.ics.uci.edu/ml/datasets/glass+identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bc335a708fcf8457a3fb03177490239a",
     "grade": false,
     "grade_id": "cell-d9f69f87f6185062",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f11b1b4c30e5bc920b79594631324428",
     "grade": false,
     "grade_id": "cell-663f2fdb10f38c5f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_csv_into_numpy():\n",
    "    \"Load csv, then split into data and targets\"\n",
    "    df = pd.read_csv('glass.csv')\n",
    "    X = df.drop(columns='Type')\n",
    "    X= np.array(X)\n",
    "    y = df['Type']\n",
    "    y = np.array(y)\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4a28b864f93b759422c05dd8c4d43ca",
     "grade": true,
     "grade_id": "cell-4a9bef901003e9a0",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3 points\n",
    "Test code for the 'load_csv_into_numpy' function. \n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "\n",
    "X, y = load_csv_into_numpy()\n",
    "\n",
    "assert type(X) == np.ndarray\n",
    "assert X.shape == (214, 9)\n",
    "assert list(X[-1]) == [1.51711, 14.23,  0.,  2.08, 73.36,  0., 8.62,  1.67,  0.]\n",
    "\n",
    "assert type(y) == np.ndarray\n",
    "assert y.shape == (214,)\n",
    "assert list(np.unique(y)) == [1.0, 2.0, 3.0, 5.0, 6.0, 7.0]\n",
    "assert y[-1] == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be10df1ec1b7fd70b8b249e10b63eb64",
     "grade": false,
     "grade_id": "cell-88cacb6c7b8a5b37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b21b182137691e0edbe07692ef8b8a8a",
     "grade": false,
     "grade_id": "cell-47ca072821ac2e94",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# We get to reuse our earlier code. Functions are 🆒\n",
    "pipelines = make_pipelines()\n",
    "fit_pipelines(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3dba95394582543206dd60af74eecd7e",
     "grade": false,
     "grade_id": "cell-1b60c7764a5bb5f3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def order_models_glass_data() -> List[str]:\n",
    "    \"\"\"Order models from best to worst on `score`. \n",
    "    Create the list manually  or write code.\n",
    "    Return a list of names\n",
    "    \n",
    "    For informational purposes, list of scores: [0.68519, 0.64815, 0.62963, 0.59259, 0.35185] \n",
    "\n",
    "    \"\"\"\n",
    "    models_best_to_worst = [(pipe.steps[0][1].__class__.__name__, pipe.score(X_test, y_test)) \\\n",
    "                            for pipe in pipelines]\n",
    "    models_best_to_worst.sort(key=lambda x: x[1], reverse=True)\n",
    "    models_best_to_worst = [x[0] for x in models_best_to_worst]\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    return models_best_to_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8efabd31cc50253fed8af3d3f0806032",
     "grade": true,
     "grade_id": "cell-423c25965f9837ab",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2 points\n",
    "Test code for the 'order_models' function. \n",
    "There are hidden tests. They will make sure all the models are in order\n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "\n",
    "models_best_to_worst = order_models_glass_data()\n",
    "assert len(models_best_to_worst) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DecisionTreeClassifier',\n",
       " 'SVC',\n",
       " 'KNeighborsClassifier',\n",
       " 'LogisticRegression',\n",
       " 'GaussianNB']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best_to_worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bafad1b5caab11b7f8d70f45a2ef5a85",
     "grade": false,
     "grade_id": "cell-d151cfd95a5757c9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's improve the KNeighborsClassifier for the glass data with Grid Search\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "26fc5f09178714ad0454d46cbb44b1b7",
     "grade": false,
     "grade_id": "cell-3615ec60e81cf892",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aa8e7c90e8e7b8024cd6651f48c82ff2",
     "grade": false,
     "grade_id": "cell-f0afb4e4a9682710",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def grid_search_knn():\n",
    "    \"\"\"\n",
    "    1. Create a pipeline with PCA into k-NN.\n",
    "    2. Define a grid search for n_components of PCA and n_neighbors of k-NN\n",
    "    3. Conduct grid search\n",
    "    4. Return score (accuracy) and dictionary of best parameters\n",
    "    \"\"\"\n",
    "    pipeline_knn = Pipeline([('pca', PCA()),\n",
    "                         ('clf', KNeighborsClassifier())])\n",
    "    \n",
    "    grid_params = dict(pca__n_components=range(1,10),\n",
    "                       clf__n_neighbors=range(1,10))\n",
    "    \n",
    "    gs = GridSearchCV(estimator = pipeline_knn,\n",
    "                      param_grid =  grid_params,\n",
    "                      scoring = 'accuracy')\n",
    "    gs.fit(X_train, y_train)\n",
    "    accuracy = gs.score(X_test, y_test)\n",
    "    best_params = gs.best_params_\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    return accuracy, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "12b0b277615dd1532fc5b152ecfc51ae",
     "grade": true,
     "grade_id": "cell-9e701707803767cc",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8 points\n",
    "Test code for the 'grid_search_knn' function. \n",
    "There are hidden tests. \n",
    "This cell should NOT give any errors when it is run.\n",
    "\"\"\"\n",
    "accuracy, best_params = grid_search_knn()\n",
    "\n",
    "assert accuracy == 0.7407407407407407\n",
    "assert list(best_params.keys()) == ['clf__n_neighbors', 'pca__n_components']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71b7fb1d3e35d3ee2e4f96708f05812e",
     "grade": false,
     "grade_id": "cell-55b376a336919412",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Bonus Cartoon\n",
    "------\n",
    "\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/data_pipeline.png\" width=\"75%\"/></center>\n",
    "\n",
    "> \"Is the pipeline literally running from your laptop?\"   \n",
    "> \"Don't be silly, my laptop disconnects far too often to host a service we rely on. It's running on my phone.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "09a2aa8aba527974e6dca328efeb0bce",
     "grade": false,
     "grade_id": "cell-ff2d070e25115ec4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
